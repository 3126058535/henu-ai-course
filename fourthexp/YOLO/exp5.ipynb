{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 练习9-车辆识别\n",
    "--------\n",
    "## 介绍\n",
    "\n",
    "在本练习中，我们将将使用YOLO模型进行识别和定位车辆。\n",
    "\n",
    "\n",
    "在开始练习前，需要**下载如下的数据文件进行上传**：\n",
    "\n",
    "- images.tgz -数据集\n",
    "- model_data.tgz -预训练模型\n",
    "- out.tgz -输出文件存放\n",
    "\n",
    "在整个练习中，涉及如下的**作业**：\n",
    "\n",
    "| 作业 | 分值 |\n",
    "|--|--|\n",
    "|[利用种类分值门槛进行过滤](#1)| 20分|\n",
    "|[实现交并比的计算](#2)|10分|\n",
    "|[实现非最大抑制](#3)|20分|\n",
    "|[包装过滤器](#4)|30分|\n",
    "|[实现模型预测方法](#5)|20分|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入相关的包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/\n",
      "images/0001.jpg\n",
      "images/0002.jpg\n",
      "images/0003.jpg\n",
      "images/0004.jpg\n",
      "images/0005.jpg\n",
      "images/0006.jpg\n",
      "images/0007.jpg\n",
      "images/0008.jpg\n",
      "images/0009.jpg\n",
      "images/0010.jpg\n",
      "images/0011.jpg\n",
      "images/0012.jpg\n",
      "images/0013.jpg\n",
      "images/0014.jpg\n",
      "images/0015.jpg\n",
      "images/0016.jpg\n",
      "images/0017.jpg\n",
      "images/0018.jpg\n",
      "images/0019.jpg\n",
      "images/0020.jpg\n",
      "images/0021.jpg\n",
      "images/0022.jpg\n",
      "images/0023.jpg\n",
      "images/0024.jpg\n",
      "images/0025.jpg\n",
      "images/0026.jpg\n",
      "images/0027.jpg\n",
      "images/0028.jpg\n",
      "images/0029.jpg\n",
      "images/0030.jpg\n",
      "images/0031.jpg\n",
      "images/0032.jpg\n",
      "images/0033.jpg\n",
      "images/0034.jpg\n",
      "images/0035.jpg\n",
      "images/0036.jpg\n",
      "images/0037.jpg\n",
      "images/0038.jpg\n",
      "images/0039.jpg\n",
      "images/0040.jpg\n",
      "images/0041.jpg\n",
      "images/0042.jpg\n",
      "images/0043.jpg\n",
      "images/0044.jpg\n",
      "images/0045.jpg\n",
      "images/0046.jpg\n",
      "images/0047.jpg\n",
      "images/0048.jpg\n",
      "images/0049.jpg\n",
      "images/0050.jpg\n",
      "images/0051.jpg\n",
      "images/0052.jpg\n",
      "images/0053.jpg\n",
      "images/0054.jpg\n",
      "images/0055.jpg\n",
      "images/0056.jpg\n",
      "images/0057.jpg\n",
      "images/0058.jpg\n",
      "images/0059.jpg\n",
      "images/0060.jpg\n",
      "images/0061.jpg\n",
      "images/0062.jpg\n",
      "images/0063.jpg\n",
      "images/0064.jpg\n",
      "images/0065.jpg\n",
      "images/0066.jpg\n",
      "images/0067.jpg\n",
      "images/0068.jpg\n",
      "images/0069.jpg\n",
      "images/0070.jpg\n",
      "images/0071.jpg\n",
      "images/0072.jpg\n",
      "images/0073.jpg\n",
      "images/0074.jpg\n",
      "images/0075.jpg\n",
      "images/0076.jpg\n",
      "images/0077.jpg\n",
      "images/0078.jpg\n",
      "images/0079.jpg\n",
      "images/0080.jpg\n",
      "images/0081.jpg\n",
      "images/0082.jpg\n",
      "images/0083.jpg\n",
      "images/0084.jpg\n",
      "images/0085.jpg\n",
      "images/0086.jpg\n",
      "images/0087.jpg\n",
      "images/0088.jpg\n",
      "images/0089.jpg\n",
      "images/0090.jpg\n",
      "images/0091.jpg\n",
      "images/0092.jpg\n",
      "images/0093.jpg\n",
      "images/0094.jpg\n",
      "images/0095.jpg\n",
      "images/0096.jpg\n",
      "images/0097.jpg\n",
      "images/0098.jpg\n",
      "images/0099.jpg\n",
      "images/0100.jpg\n",
      "images/0101.jpg\n",
      "images/0102.jpg\n",
      "images/0103.jpg\n",
      "images/0104.jpg\n",
      "images/0105.jpg\n",
      "images/0106.jpg\n",
      "images/0107.jpg\n",
      "images/0108.jpg\n",
      "images/0109.jpg\n",
      "images/0110.jpg\n",
      "images/0111.jpg\n",
      "images/0112.jpg\n",
      "images/0113.jpg\n",
      "images/0114.jpg\n",
      "images/0115.jpg\n",
      "images/0116.jpg\n",
      "images/0117.jpg\n",
      "images/0118.jpg\n",
      "images/0119.jpg\n",
      "images/0120.jpg\n",
      "images/giraffe.jpg\n",
      "images/test.jpg\n",
      "tar (child): model_data.tgz: Cannot open: No such file or directory\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n",
      "out/\n",
      "yad2k/\n",
      "yad2k/models/\n",
      "yad2k/utils/\n",
      "yad2k/models/keras_darknet19.py\n",
      "yad2k/models/keras_yolo.py\n",
      "yad2k/models/__pycache__/\n",
      "yad2k/utils/utils.py\n",
      "yad2k/utils/__init__.py\n",
      "yad2k/utils/__pycache__/\n",
      "yad2k/models/__pycache__/keras_darknet19.cpython-36.pyc\n",
      "yad2k/models/__pycache__/keras_darknet19.cpython-37.pyc\n",
      "yad2k/models/__pycache__/keras_yolo.cpython-36.pyc\n",
      "yad2k/models/__pycache__/keras_yolo.cpython-37.pyc\n",
      "yad2k/utils/__pycache__/utils.cpython-36.pyc\n",
      "yad2k/utils/__pycache__/utils.cpython-37.pyc\n",
      "yad2k/utils/__pycache__/__init__.cpython-36.pyc\n",
      "yad2k/utils/__pycache__/__init__.cpython-37.pyc\n"
     ]
    }
   ],
   "source": [
    "#加载时间较长\n",
    "!tar xzvf images.tgz\n",
    "!tar xzvf model_data.tgz\n",
    "!tar xzvf out.tgz\n",
    "!tar xzvf yad2k.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(19*19, 5, 1)\n",
    "b = np.random.randn(19*19, 5, 80)\n",
    "c = a * b # shape of c will be (19*19, 5, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对每个box\n",
    "    1. 找出最高分的分类(80选1)\n",
    "    2. 得出相应的分数\n",
    "2. 创建一个门槛mask：比如 ([0.9, 0.3, 0.4, 0.5, 0.1] < 0.4) 返回 [False, True, False, False, True] 注意你想保留的boxes应该为true\n",
    "3. 利用 TensorFlow 将 mask 应用到 box_class_scores 上，过滤掉不需要的boxes。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
    "    \"\"\"通过对对象和类的置信度设置阈值来过滤YOLO框。\n",
    "    \"\"\"\n",
    "    # Step 1: Compute box scores\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "\n",
    "    # Step 2: 通过最大的box_scores查找box_classes，跟踪相应得分\n",
    "    box_classes = K.argmax(box_scores, axis=-1)\n",
    "    box_class_scores = K.max(box_scores, axis=-1)\n",
    "\n",
    "    # Step 3: 使用“阈值”基于“ box_class_scores”创建过滤掩码\n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "\n",
    "    # Step 4: Apply the mask to scores, boxes and classes\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "\n",
    "    return scores, boxes, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0515 07:25:16.103945 140737354041152 deprecation.py:323] From /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 10.750582\n",
      "boxes[2] = [ 8.426533   3.2713668 -0.5313436 -4.9413733]\n",
      "classes[2] = 7\n",
      "scores.shape = (?,)\n",
      "boxes.shape = (?, 4)\n",
      "classes.shape = (?,)\n"
     ]
    }
   ],
   "source": [
    "#测试yolo_filter_boxes\n",
    "with tf.Session() as test_a:\n",
    "    box_confidence = tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random_normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "    box_class_probs = tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = 0.5)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.shape))\n",
    "    print(\"classes.shape = \" + str(classes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**：\n",
    "```\n",
    "scores[2] = 10.7506\n",
    "boxes[2] = [ 8.42653275  3.27136683 -0.5313437  -4.94137383]\n",
    "classes[2] = 7\n",
    "scores.shape = (?,)\n",
    "boxes.shape = (?, 4)\n",
    "classes.shape = (?,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\"在box1和box2之间实现联合交叉（IoU）\n",
    "    \"\"\"\n",
    "    xi1 = max(box1[0], box2[0])\n",
    "    yi1 = max(box1[1], box2[1])\n",
    "    xi2 = min(box1[2], box2[2])\n",
    "    yi2 = min(box1[3], box2[3])\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou = 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "#测试iou\n",
    "box1 = (2, 1, 4, 3)\n",
    "box2 = (1, 2, 3, 4) \n",
    "print(\"iou = \" + str(iou(box1, box2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**:\n",
    "```\n",
    "iou = 0.14285714285714285\n",
    "```\n",
    "\n",
    "现在你准备好实现非最大抑制了。关键步骤为：\n",
    "1. 选出具有最高分数的box\n",
    "2. 计算该box和其他box的iou, 删除重叠部分iou大于 iou_threshold 的 box\n",
    "3. 循环1，2 直到没有满足条件的 boxes\n",
    "\n",
    "这样将会删除所有有大量重叠覆盖的的 boxes，只留下最优的。\n",
    "\n",
    "**练习：使用 TensorFlow 实现 yolo_non_max_suppression()**\n",
    "\n",
    "TensorFlow有用的方法：\n",
    "<span id='3'></span>\n",
    "- tf.image.non_max_suppression() # 不需要用你自己的 iou 方法了\n",
    "- K.gather()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes=10, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    对一组方框应用非最大抑制(NMS)\n",
    "    \"\"\"\n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32') \n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))\n",
    "\n",
    "    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes, iou_threshold)\n",
    "\n",
    "    scores = K.gather(scores, nms_indices)\n",
    "    boxes = K.gather(boxes, nms_indices)\n",
    "    classes = K.gather(classes, nms_indices)\n",
    "\n",
    "    return scores, boxes, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0515 07:26:07.069611 140737354041152 module_wrapper.py:139] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0515 07:26:07.070883 140737354041152 module_wrapper.py:139] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0515 07:26:07.071945 140737354041152 module_wrapper.py:139] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "W0515 07:26:07.082874 140737354041152 module_wrapper.py:139] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 6.938395\n",
      "boxes[2] = [-5.299932    3.1379814   4.450367    0.95942086]\n",
      "classes[2] = -2.2452729\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#测试yolo_non_max_suppression\n",
    "\n",
    "with tf.Session() as test_b:\n",
    "    scores = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "    classes = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**：\n",
    "```\n",
    "scores[2] = 6.9384\n",
    "boxes[2] = [-5.299932    3.13798141  4.45036697  0.95942086]\n",
    "classes[2] = -2.24527\n",
    "scores.shape = (10,)\n",
    "boxes.shape = (10, 4)\n",
    "classes.shape = (10,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 包装过滤器<span id='4'></span>\n",
    "接下来我们需要实现深度卷积神经网络（CNN）(19x19x5x85)\n",
    "\n",
    "**练习：实现 yolo_eval()**\n",
    "\n",
    "yolo_eval 方法将YOLO 的输出进行编码并用非最大抑制进行过滤。\n",
    "\n",
    "表示 box 的方式由好多种，比如左上角/右下角的坐标，比如中心和宽高。YOLO 在运算过程中将灵活转换这些表示方式。\n",
    "```python\n",
    "# (x,y,w,h) -->  (x1, y1, x2, y2)\n",
    "# 用于符合yolo_filter_boxes的输入\n",
    "boxes = yolo_boxes_to_corners(box_xy, box_wh) \n",
    "# 格局图片大小调整 box 大小\n",
    "boxes = scale_boxes(boxes, image_shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape=(720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    \"\"\"\n",
    "    将YOLO编码的输出（很多盒子）连同它们的分数，盒子坐标和类一起转换为预测的盒子。\n",
    "    \"\"\"\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, score_threshold)\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n",
    "\n",
    "    return scores, boxes, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 138.79124\n",
      "boxes[2] = [1292.3297  -278.52167 3876.9893  -835.56494]\n",
      "classes[2] = 54\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#测试yolo_eval\n",
    "\n",
    "with tf.Session() as test_b:\n",
    "    yolo_outputs = (tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))\n",
    "    scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**：\n",
    "```\n",
    "\n",
    "scores[2] = 138.791\n",
    "boxes[2] = [ 1292.32971191  -278.52166748  3876.98925781  -835.56494141]\n",
    "classes[2] = 54\n",
    "scores.shape = (10,)\n",
    "boxes.shape = (10, 4)\n",
    "classes.shape = (10,)\n",
    "```\n",
    "\n",
    "**YOLO 的总结**\n",
    "- 输入图片(608, 608, 3)\n",
    "- 输入的图片经过一个 CNN，得到一个输出(19,19,5,85)\n",
    "- 展开图片的后两个维度，得到 (19, 19, 425)\n",
    "- 19x19 中的每个单元格都包含了图片的425个数\n",
    "- 425 = 5 x 85 因为每个单元格包含5个预测 boxes, 对于5个 anchor boxes\n",
    "- 85 = 5 + 80 其中5表示(pc,bx,by,bh,bw)，80代表要检测的分类数\n",
    "- 然后基于以下规则挑选一些 boxes\n",
    "    - 分值门槛：扔掉预测值低于门槛的 boxes\n",
    "    - 非最大抑制：计算 iou，避免重叠的同一个对象识别\n",
    "- 给出 YOLO 的最后输出\n",
    "\n",
    "## 3 测试训练好了的 YOLO 模型\n",
    "创建session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 定义classes, anchers 和 图片大小\n",
    "classes和anchers文件是分开的，另外原始文件是(720, 1280)的，我们可以处理成(608, 608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_data/coco_classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ea6ba3508ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_data/coco_classes.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_data/yolo_anchors.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m720.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1280.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yolo_utils.py\u001b[0m in \u001b[0;36mread_classes\u001b[0;34m(classes_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_data/coco_classes.txt'"
     ]
    }
   ],
   "source": [
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "image_shape = (720., 1280.)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 导入预训练模型\n",
    "模型来自the official YOLO website的文件——`yolo.h5`。\n",
    ">注意利用前文程序将图片(m, 608, 608, 3) 转换为 (m, 19, 19, 5, 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 608, 608, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 608, 608, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 608, 608, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 608, 608, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 304, 304, 32) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 304, 304, 64) 18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 304, 304, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 304, 304, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 152, 152, 64) 0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 152, 152, 128 73728       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 152, 152, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 152, 152, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 152, 152, 64) 8192        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 152, 152, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 152, 152, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 152, 152, 128 73728       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 152, 152, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 152, 152, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 76, 76, 128)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 76, 76, 256)  294912      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 76, 76, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 76, 76, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 76, 76, 128)  32768       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 76, 76, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 76, 76, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 76, 76, 256)  294912      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 76, 76, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 76, 76, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 38, 38, 256)  0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 38, 38, 512)  1179648     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 38, 38, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 38, 38, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 38, 38, 256)  131072      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 38, 38, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 38, 38, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 38, 38, 512)  1179648     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 38, 38, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 38, 38, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 38, 38, 256)  131072      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 38, 38, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 38, 38, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 38, 38, 512)  1179648     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 38, 38, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 38, 38, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 19, 19, 512)  0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 19, 19, 1024) 4718592     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 19, 19, 1024) 4096        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 19, 19, 512)  524288      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 19, 19, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 19, 19, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 19, 19, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 19, 19, 1024) 4096        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 19, 19, 512)  524288      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 19, 19, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 19, 19, 512)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 19, 19, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 19, 19, 1024) 4096        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 19, 19, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 19, 19, 1024) 4096        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 38, 38, 64)   32768       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 38, 38, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 19, 19, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 38, 38, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 19, 19, 1024) 4096        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "space_to_depth_x2 (Lambda)      (None, 19, 19, 256)  0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 19, 19, 1280) 0           space_to_depth_x2[0][0]          \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 19, 19, 1024) 11796480    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 19, 19, 1024) 4096        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 19, 19, 425)  435625      leaky_re_lu_22[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 50,983,561\n",
      "Trainable params: 50,962,889\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model(\"model_data/yolov2.h5\")\n",
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 将模型输出转换为识别框tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来将yolo_ouput 传给模型的 yolo_eval\n",
    "\n",
    "### 3.4 过滤boxes\n",
    "yolo_ouput 已经将输出的格式调整好了，调用前文程序 yolo_eval 选出最好的boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 在图片上运行模型\n",
    "<span id='5'></span>\n",
    "\n",
    "步骤：\n",
    "1. 创建session\n",
    "2. yolo_model.input 给到 yolo_model 计算输出 yolo_model.output\n",
    "3. yolo_model.output 给到 yolo_head，转换为 yolo_output\n",
    "4. yolo_output 经过过滤-yolo_eval，输出预测的接轨：scores, boxes, classes\n",
    "\n",
    "**练习：实现模型预测方法 yolo_predict**\n",
    "\n",
    "提示方法：\n",
    "```python\n",
    "image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "```\n",
    "\n",
    "方法输出：\n",
    "\n",
    "- image: 用于在图片上画出 boxes 的 PIL 表示，这里你不需要用它\n",
    "- image_data: 一个 numpy-array 表示的图片，经作为 CNN 的输入\n",
    "\n",
    "当模型使用 BatchNorm 时，`feed_dict {K.learning_phase(): 0} `中需要多一个占位符 placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, image_file):\n",
    "    \"\"\"\n",
    "    运行存储在“ sess”中的图形以预测“ image_file”的框。 打印并绘制预测值。\n",
    "\n",
    "    参数:\n",
    "    sess -- 包含YOLO图的tensorflow / Keras会话\n",
    "    image_file -- 存储在“images”文件夹中的图像的名称\n",
    "\n",
    "    返回值:\n",
    "    out_scores -- 形状张量（None，），预测盒的分数\n",
    "    out_boxes -- 形状的张量（None，4），预测框的坐标\n",
    "    out_classes -- 形状张量（None，），预测框的类索引\n",
    "\n",
    "    Note: “ None”实际上代表预测的盒子数，在0到max_boxes之间变化。 \n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "\n",
    "    # 使用正确的张量运行会话，并在feed_dict中选择正确的占位符。\n",
    "    # feed_dict={yolo_model.input: ... , K.learning_phase(): 0})\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    out_scores, out_boxes, out_classes =  \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = generate_colors(class_names)\n",
    "    # Draw bounding boxes on the image file\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    # Save the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
    "    # Display the results in the notebook\n",
    "    output_image = scipy.misc.imread(os.path.join(\"out\", image_file))\n",
    "    imshow(output_image)\n",
    "\n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 在 tset.jpg 上进行测试 \n",
    "out_scores, out_boxes, out_classes = predict(sess, \"test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**：\n",
    "```\n",
    " Found 7 boxes for test.jpg\n",
    " car 0.60 (925, 285) (1045, 374)\n",
    " car 0.66 (706, 279) (786, 350)\n",
    " bus 0.67 (5, 266) (220, 407)\n",
    " car 0.70 (947, 324) (1280, 705)\n",
    " car 0.74 (159, 303) (346, 440)\n",
    " car 0.80 (761, 282) (942, 412)\n",
    " car 0.89 (367, 300) (745, 648)\n",
    "```\n",
    "刚才运行的模型可以识别 coco_classes.txt 列出的 80 个种类，你可以自己试一下。\n",
    "\n",
    "**谨记**\n",
    "- YOLO 是一个高水平的检测模型，迅速又准确\n",
    "- 输入图片通过 CNN 输出 19x19x5x85 的维度\n",
    "- 可以认为 19x19 中的每个单元格都包含 5 个 boxes 的信息\n",
    "- 过滤器使用非最大抑制进行过滤\n",
    "    - 门槛过滤器过滤掉低分的识别，只留下高分的识别\n",
    "    - 利用IOU门槛识别消除重叠的boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

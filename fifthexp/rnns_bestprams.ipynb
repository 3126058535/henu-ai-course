{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "33/33 [==============================] - 3s 39ms/step - loss: 0.1262 - val_loss: 0.0670\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.0172 - val_loss: 0.0786\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0126 - val_loss: 0.0037\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0089 - val_loss: 0.0160\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0064 - val_loss: 0.0352\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0052 - val_loss: 0.0207\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0048 - val_loss: 0.0307\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0046 - val_loss: 0.0255\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0037 - val_loss: 0.0246\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0031 - val_loss: 0.0069\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0029 - val_loss: 0.0077\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0027 - val_loss: 0.0097\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0023 - val_loss: 0.0091\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0020 - val_loss: 0.0092\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0019 - val_loss: 0.0084\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0018 - val_loss: 0.0071\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 60, 100)           10200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 60, 100)           0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,401\n",
      "Trainable params: 30,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os,math\n",
    "from keras.layers import Dropout, Dense, SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# 支持中文\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "data = pd.read_csv(\"SH600519.csv\")  # 读取股票文件\n",
    "training_set = data.iloc[0:2426 - 300, 2:3].values  \n",
    "\n",
    "\n",
    "test_set = data.iloc[2426 - 300:, 2:3].values  \n",
    "sc           = MinMaxScaler(feature_range=(0, 1))\n",
    "training_set = sc.fit_transform(training_set)\n",
    "test_set     = sc.transform(test_set) \n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in range(60, len(training_set)):\n",
    "    x_train.append(training_set[i - 60:i, 0])\n",
    "    y_train.append(training_set[i, 0])\n",
    "    \n",
    "for i in range(60, len(test_set)):\n",
    "    x_test.append(test_set[i - 60:i, 0])\n",
    "    y_test.append(test_set[i, 0])\n",
    "    \n",
    "# 对训练集进行打乱\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "x_train, y_train = np.array(x_train), np.array(y_train) # x_train形状为：(2066, 60, 1)\n",
    "x_test,  y_test  = np.array(x_test),  np.array(y_test)\n",
    "\n",
    "\"\"\"\n",
    "输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]\n",
    "\"\"\"\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 60, 1))\n",
    "x_test  = np.reshape(x_test,  (x_test.shape[0], 60, 1))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(100, return_sequences=True), #布尔值。是返回输出序列中的最后一个输出，还是全部序列。\n",
    "    Dropout(0.1),                         #防止过拟合\n",
    "    SimpleRNN(100),\n",
    "    Dropout(0.1),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error')  # 损失函数用均方误差\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    validation_freq=1)                  #测试的epoch间隔数\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss']    , label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss by K同学啊')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted_stock_price = model.predict(x_test)                       # 测试集输入模型进行预测\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price) # 对预测数据还原---从（0，1）反归一化到原始范围\n",
    "real_stock_price = sc.inverse_transform(test_set[60:])              # 对真实数据还原---从（0，1）反归一化到原始范围\n",
    "\n",
    "# 画出真实数据和预测数据的对比曲线\n",
    "plt.plot(real_stock_price, color='red', label='Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted Stock Price')\n",
    "plt.title('Stock Price Prediction by K同学啊')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gloomy\\AppData\\Local\\Temp\\ipykernel_40384\\2521160233.py:18: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, epochs=20, batch_size=64, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.000213 using {'dropout_rate': 0.3, 'learning_rate': 0.001, 'units': 100}\n",
      "-0.000247 (0.000032) with: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'units': 50}\n",
      "-0.000274 (0.000118) with: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'units': 100}\n",
      "-0.000327 (0.000184) with: {'dropout_rate': 0.1, 'learning_rate': 0.001, 'units': 150}\n",
      "-0.002102 (0.001247) with: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'units': 50}\n",
      "-0.027256 (0.034163) with: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'units': 100}\n",
      "-0.086417 (0.022608) with: {'dropout_rate': 0.1, 'learning_rate': 0.01, 'units': 150}\n",
      "-0.057893 (0.024643) with: {'dropout_rate': 0.1, 'learning_rate': 0.1, 'units': 50}\n",
      "-0.096409 (0.023201) with: {'dropout_rate': 0.1, 'learning_rate': 0.1, 'units': 100}\n",
      "-0.100457 (0.007460) with: {'dropout_rate': 0.1, 'learning_rate': 0.1, 'units': 150}\n",
      "-0.000416 (0.000133) with: {'dropout_rate': 0.2, 'learning_rate': 0.001, 'units': 50}\n",
      "-0.000318 (0.000049) with: {'dropout_rate': 0.2, 'learning_rate': 0.001, 'units': 100}\n",
      "-0.000828 (0.000235) with: {'dropout_rate': 0.2, 'learning_rate': 0.001, 'units': 150}\n",
      "-0.001346 (0.001108) with: {'dropout_rate': 0.2, 'learning_rate': 0.01, 'units': 50}\n",
      "-0.011554 (0.011559) with: {'dropout_rate': 0.2, 'learning_rate': 0.01, 'units': 100}\n",
      "-0.088346 (0.077436) with: {'dropout_rate': 0.2, 'learning_rate': 0.01, 'units': 150}\n",
      "-0.080162 (0.005956) with: {'dropout_rate': 0.2, 'learning_rate': 0.1, 'units': 50}\n",
      "-0.106347 (0.034681) with: {'dropout_rate': 0.2, 'learning_rate': 0.1, 'units': 100}\n",
      "-0.209905 (0.128696) with: {'dropout_rate': 0.2, 'learning_rate': 0.1, 'units': 150}\n",
      "-0.000276 (0.000063) with: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'units': 50}\n",
      "-0.000213 (0.000015) with: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'units': 100}\n",
      "-0.000566 (0.000272) with: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'units': 150}\n",
      "-0.001197 (0.001068) with: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'units': 50}\n",
      "-0.014593 (0.015162) with: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'units': 100}\n",
      "-0.079055 (0.006849) with: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'units': 150}\n",
      "-0.087222 (0.014042) with: {'dropout_rate': 0.3, 'learning_rate': 0.1, 'units': 50}\n",
      "-0.063101 (0.035335) with: {'dropout_rate': 0.3, 'learning_rate': 0.1, 'units': 100}\n",
      "-0.101601 (0.037190) with: {'dropout_rate': 0.3, 'learning_rate': 0.1, 'units': 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# 定义创建模型的函数\n",
    "def create_model(units=100, dropout_rate=0.1, learning_rate=0.001):\n",
    "    model = tf.keras.Sequential([\n",
    "        SimpleRNN(units, return_sequences=True),\n",
    "        Dropout(dropout_rate),\n",
    "        SimpleRNN(units),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 创建 KerasRegressor\n",
    "model = KerasRegressor(build_fn=create_model, epochs=20, batch_size=64, verbose=0)\n",
    "\n",
    "# 定义搜索的参数网格\n",
    "param_grid = {\n",
    "    'units': [50, 100, 150],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "\n",
    "# 输出结果\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# 最佳模型\n",
    "best_model = grid_result.best_estimator_.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gloomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
